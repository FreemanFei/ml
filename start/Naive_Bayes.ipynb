{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ham_dir = '../data/email/ham/'\n",
    "spam_dir = '../data/email/spam/'\n",
    "test_dir = '../data/email/test/'\n",
    "path_ham = os.listdir(ham_dir)\n",
    "path_spam = os.listdir(spam_dir)\n",
    "path_test = os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def re_sign( string ):\n",
    "    return  re.sub('[^a-zA-Z0-9]',\"\",string).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_txt( path_txt, path_dir):\n",
    "    all_txt = []\n",
    "    for line in path_txt:\n",
    "        f = open(path_dir+line)\n",
    "        tmp = []\n",
    "        for line in f:\n",
    "            for word in line.replace('\\n','').split(' '):\n",
    "                tmp.append( re_sign( word ) )\n",
    "        tmp_new = []\n",
    "        for word in tmp:\n",
    "            if word != '':\n",
    "                tmp_new.append(word)\n",
    "        all_txt.append( ' '.join(tmp_new) )\n",
    "    return all_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ham = load_txt( path_ham, ham_dir)\n",
    "all_spam = load_txt( path_spam, spam_dir)\n",
    "all_test = load_txt( path_test, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorizer=CountVectorizer(stop_words='english')\n",
    "vectorizer=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_ham = ' '.join(all_ham)\n",
    "tmp_spam = ' '.join(all_spam)\n",
    "#tmp_test = ' '.join(all_test)\n",
    "tmp_all = [tmp_ham, tmp_spam]\n",
    "corpusTotoken=vectorizer.fit_transform(tmp_all).todense()\n",
    "corpusName = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0,  0,  0, ...,  0,  2,  0],\n",
       "        [ 2,  2, 19, ..., 10,  0,  1]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusTotoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = corpusTotoken.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prob_spam = []\n",
    "prob_ham = []\n",
    "test = corpusTotoken.tolist()\n",
    "matrix_sum = []\n",
    "for i in range(len(test[0])):\n",
    "    matrix_sum.append( int(test[0][i]) + int(test[1][i]) )\n",
    "    \n",
    "for i in range( len(matrix_sum) ):\n",
    "    try:\n",
    "        prob_spam.append( test[1][i]/float(matrix_sum[i]) )\n",
    "        prob_ham.append( test[0][i]/float(matrix_sum[i]) )\n",
    "    except:\n",
    "        prob_spam.append(0.0)\n",
    "        prob_ham.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_prob = len(all_spam)/float( len(all_ham)+len(all_spam) )\n",
    "ham_prob = len(all_ham)/float( len(all_ham)+len(all_spam) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham ham_24.txt\n",
      "ham ham_3.txt\n",
      "ham ham_4.txt\n",
      "spam spam_11.txt\n",
      "spam spam_14.txt\n",
      "ham spam_17.txt\n",
      "spam spam_18.txt\n",
      "spam spam_19.txt\n",
      "spam spam_22.txt\n",
      "spam spam_8.txt\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_test)):\n",
    "    line = all_test[i]\n",
    "    tmp_prob_spam = 0\n",
    "    tmp_prob_ham = 0\n",
    "    for word in line.split(' '):\n",
    "        try:\n",
    "            index = corpusName.index(word)\n",
    "            tmp_prob_spam += (prob_spam[index]*spam_prob)/float( prob_spam[index]*spam_prob+ prob_ham[index]*ham_prob )   \n",
    "            tmp_prob_ham += (prob_ham[index]*ham_prob)/float( prob_spam[index]*spam_prob+ prob_ham[index]*ham_prob )\n",
    "        except:\n",
    "            continue\n",
    "    tmp_string = ''\n",
    "    if tmp_prob_spam < tmp_prob_ham:\n",
    "        tmp_string = 'ham'\n",
    "    else:\n",
    "        tmp_string = 'spam'\n",
    "    print tmp_string, path_test[i]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
